#!/usr/bin/env python3
"""
çœŸå®éŸ³é¢‘æµ‹è¯•è„šæœ¬ - ç”ŸæˆåŒ…å«ä¿¡å·çš„éŸ³é¢‘æ•°æ®è¿›è¡Œæµ‹è¯•
"""

import asyncio
import aiohttp
import numpy as np
import struct
import math


def generate_test_audio(duration=2.0, sample_rate=16000, frequency=440.0, amplitude=0.1):
    """
    ç”Ÿæˆæµ‹è¯•éŸ³é¢‘æ•°æ®ï¼ˆæ­£å¼¦æ³¢ï¼‰
    
    Args:
        duration: éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
        sample_rate: é‡‡æ ·ç‡
        frequency: é¢‘ç‡ï¼ˆHzï¼‰
        amplitude: æŒ¯å¹…ï¼ˆ0-1ï¼‰
    
    Returns:
        bytes: WAVæ ¼å¼çš„éŸ³é¢‘æ•°æ®
    """
    # ç”Ÿæˆæ­£å¼¦æ³¢
    samples = int(duration * sample_rate)
    t = np.linspace(0, duration, samples, False)
    
    # ç”Ÿæˆ440Hzçš„æ­£å¼¦æ³¢ï¼ˆAéŸ³ï¼‰
    audio_signal = amplitude * np.sin(2 * np.pi * frequency * t)
    
    # è½¬æ¢ä¸º16ä½æ•´æ•°
    audio_int16 = (audio_signal * 32767).astype(np.int16)
    
    # åˆ›å»ºWAVæ–‡ä»¶å¤´
    wav_header = bytearray([
        0x52, 0x49, 0x46, 0x46,  # "RIFF"
        0x00, 0x00, 0x00, 0x00,  # æ–‡ä»¶å¤§å°ï¼ˆç¨åå¡«å……ï¼‰
        0x57, 0x41, 0x56, 0x45,  # "WAVE"
        0x66, 0x6D, 0x74, 0x20,  # "fmt "
        0x10, 0x00, 0x00, 0x00,  # fmt chunk size (16)
        0x01, 0x00,              # audio format (PCM)
        0x01, 0x00,              # channels (1)
        0x80, 0x3E, 0x00, 0x00,  # sample rate (16000)
        0x00, 0x7D, 0x00, 0x00,  # byte rate (16000 * 2 * 1)
        0x02, 0x00,              # block align (2)
        0x10, 0x00,              # bits per sample (16)
        0x64, 0x61, 0x74, 0x61,  # "data"
        0x00, 0x00, 0x00, 0x00,  # data sizeï¼ˆç¨åå¡«å……ï¼‰
    ])
    
    # è½¬æ¢ä¸ºå­—èŠ‚
    audio_bytes = audio_int16.tobytes()
    
    # æ›´æ–°æ–‡ä»¶å¤§å°
    total_size = len(wav_header) + len(audio_bytes) - 8
    wav_header[4:8] = total_size.to_bytes(4, 'little')
    wav_header[40:44] = len(audio_bytes).to_bytes(4, 'little')
    
    return wav_header + audio_bytes


def generate_speech_like_audio(duration=2.0, sample_rate=16000):
    """
    ç”Ÿæˆç±»ä¼¼è¯­éŸ³çš„éŸ³é¢‘æ•°æ®ï¼ˆå¤šé¢‘ç‡æ··åˆï¼‰
    """
    samples = int(duration * sample_rate)
    t = np.linspace(0, duration, samples, False)
    
    # æ··åˆå¤šä¸ªé¢‘ç‡æ¥æ¨¡æ‹Ÿè¯­éŸ³
    frequencies = [200, 400, 800, 1600]  # è¯­éŸ³çš„åŸºæœ¬é¢‘ç‡èŒƒå›´
    audio_signal = np.zeros(samples)
    
    for i, freq in enumerate(frequencies):
        amplitude = 0.1 / (i + 1)  # é€’å‡çš„æŒ¯å¹…
        audio_signal += amplitude * np.sin(2 * np.pi * freq * t)
    
    # æ·»åŠ ä¸€äº›éšæœºå™ªå£°æ¥æ¨¡æ‹Ÿè¯­éŸ³çš„å¤æ‚æ€§
    noise = np.random.normal(0, 0.01, samples)
    audio_signal += noise
    
    # æ·»åŠ åŒ…ç»œæ¥æ¨¡æ‹Ÿè¯­éŸ³çš„åŠ¨æ€å˜åŒ–
    envelope = np.exp(-t * 0.5) * (1 + 0.5 * np.sin(2 * np.pi * 2 * t))
    audio_signal *= envelope
    
    # è½¬æ¢ä¸º16ä½æ•´æ•°
    audio_int16 = (audio_signal * 32767).astype(np.int16)
    
    # åˆ›å»ºWAVæ–‡ä»¶å¤´
    wav_header = bytearray([
        0x52, 0x49, 0x46, 0x46,  # "RIFF"
        0x00, 0x00, 0x00, 0x00,  # æ–‡ä»¶å¤§å°ï¼ˆç¨åå¡«å……ï¼‰
        0x57, 0x41, 0x56, 0x45,  # "WAVE"
        0x66, 0x6D, 0x74, 0x20,  # "fmt "
        0x10, 0x00, 0x00, 0x00,  # fmt chunk size (16)
        0x01, 0x00,              # audio format (PCM)
        0x01, 0x00,              # channels (1)
        0x80, 0x3E, 0x00, 0x00,  # sample rate (16000)
        0x00, 0x7D, 0x00, 0x00,  # byte rate
        0x02, 0x00,              # block align
        0x10, 0x00,              # bits per sample (16)
        0x64, 0x61, 0x74, 0x61,  # "data"
        0x00, 0x00, 0x00, 0x00,  # data sizeï¼ˆç¨åå¡«å……ï¼‰
    ])
    
    # è½¬æ¢ä¸ºå­—èŠ‚
    audio_bytes = audio_int16.tobytes()
    
    # æ›´æ–°æ–‡ä»¶å¤§å°
    total_size = len(wav_header) + len(audio_bytes) - 8
    wav_header[4:8] = total_size.to_bytes(4, 'little')
    wav_header[40:44] = len(audio_bytes).to_bytes(4, 'little')
    
    return wav_header + audio_bytes


async def test_real_audio_recognition():
    """æµ‹è¯•çœŸå®éŸ³é¢‘è¯†åˆ«"""
    print("ğŸµ æµ‹è¯•çœŸå®éŸ³é¢‘è¯†åˆ«...")
    
    # ç”Ÿæˆä¸åŒç±»å‹çš„æµ‹è¯•éŸ³é¢‘
    test_cases = [
        ("æ­£å¼¦æ³¢éŸ³é¢‘", generate_test_audio(duration=2.0, frequency=440, amplitude=0.1)),
        ("ç±»è¯­éŸ³éŸ³é¢‘", generate_speech_like_audio(duration=2.0)),
        ("é«˜æŒ¯å¹…éŸ³é¢‘", generate_test_audio(duration=1.5, frequency=800, amplitude=0.3)),
    ]
    
    async with aiohttp.ClientSession() as session:
        for test_name, audio_data in test_cases:
            print(f"\nğŸ”Š æµ‹è¯• {test_name}...")
            print(f"   éŸ³é¢‘å¤§å°: {len(audio_data)} bytes")
            
            try:
                # å‡†å¤‡è¡¨å•æ•°æ®
                data = aiohttp.FormData()
                data.add_field('audio_file', audio_data, 
                               filename=f'{test_name.replace(" ", "_")}.wav', 
                               content_type='audio/wav')
                data.add_field('language', 'zh')
                
                async with session.post("http://localhost:8087/api/voice/recognize", 
                                        data=data) as response:
                    if response.status == 200:
                        result = await response.json()
                        print(f"âœ… è¯†åˆ«æˆåŠŸ:")
                        print(f"   è¯†åˆ«æ–‡æœ¬: '{result['text']}'")
                        print(f"   ç½®ä¿¡åº¦: {result['confidence']:.3f}")
                        print(f"   è¯­è¨€: {result['language']}")
                        print(f"   æ—¶é•¿: {result['duration']:.2f}ç§’")
                        
                        # æ˜¾ç¤ºéŸ³é¢‘ç»Ÿè®¡ä¿¡æ¯
                        if 'processing_info' in result and 'audio_stats' in result['processing_info']:
                            stats = result['processing_info']['audio_stats']
                            print(f"   éŸ³é¢‘ç»Ÿè®¡: max={stats.get('max_amplitude', 'N/A'):.3f}, "
                                  f"rms={stats.get('rms', 'N/A'):.3f}")
                        
                        if 'debug_saved_path' in result['file_info']:
                            print(f"   è°ƒè¯•æ–‡ä»¶: {result['file_info']['debug_saved_path']}")
                    else:
                        error_text = await response.text()
                        print(f"âŒ è¯†åˆ«å¤±è´¥: {response.status}")
                        print(f"   é”™è¯¯ä¿¡æ¯: {error_text}")
                        
            except Exception as e:
                print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹çœŸå®éŸ³é¢‘æµ‹è¯•")
    print("=" * 60)
    
    await test_real_audio_recognition()
    
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•å®Œæˆ")
    print("ğŸ“ è¯·æ£€æŸ¥ logs/audio/ ç›®å½•æŸ¥çœ‹ä¿å­˜çš„éŸ³é¢‘æ–‡ä»¶")
    print("ğŸ” æŸ¥çœ‹æœåŠ¡å™¨æ—¥å¿—äº†è§£è¯¦ç»†çš„éŸ³é¢‘å¤„ç†ä¿¡æ¯")


if __name__ == "__main__":
    asyncio.run(main()) 